# Rate limiting

**rate limiting** - ограничение частоты запросов к API/скорости обработки запросов

Причины для ограничения частоты запросов:
- производительность
- безопасность(защита от ddos атак)
- масштабируемость


Если вы предоставляете неограниченный доступ к своему API, вы по сути передаете всю силу и возможности пользователям. Любой желающий может использовать ваш API с какой ему угодно интенсивностью, в любое время, или же постоянно.

Владельцы API обычно используют единицу измерения “Транзакции в секунду” (TPS) для измерения лимитов по обработке данных. Некоторые системы могут иметь физические ограничения на передачу данных. Оба являются частью ограничения запросов на стороне сервера (Backend Rate Limiting).

Чтобы предотвратить перегруженность API, владельцы API часто применяют ограничение на количество запросов или количество данных, которые могут запрашивать клиенты. Это называется ограничением запросов на стороне приложения (Application Rate Limiting).

Если пользователь отправляет слишком много запросов, ограничение запросов к API может “троттлить“ клиентские соединения (пропускать некоторые входящие запросы, либо откладывать их в очередь на обработку — прим. пер.)

Однако имейте в виду, что всегда существует риск истечения времени ожидания запросов (timeout), а висящие, открытые соединения также повышают риск DoS-атак.

## Способы реализации ограничения запросов

1. Очереди запросов

2. Троттлинг

3. Алгоритмы ограничения запросов к API

**3.1 Leaky Bucket** — это алгоритм, который обеспечивает наиболее простой, интуитивно понятный подход к ограничению скорости обработки при помощи очереди, которую можно представить в виде «ведра», содержащего запросы. 
Когда запрос получен, он добавляется в конец очереди. Через равные промежутки времени первый элемент в очереди обрабатывается. 
Это также известно как очередь FIFO. Если очередь заполнена, то дополнительные запросы отбрасываются (или “утекают”).

**3.2 Fixed Window** - определяется временное окно и фиксированное кол-во запросов, которое можно обработать в течение этого временного окна.
Если счетчик > max, то запросы отбрасываются. Такой подход имеет свои слабые стороны, а именно на стыке двух окон при больших всплесках
невозможно предотвратить высокую нагрузку на сервер. Преимущество этого алгоритма состоит в том, что он обеспечивает обработку более свежих запросов, не зависая на обработке старых.

**3.3 Sliding Log** - Данный алгоритм предполагает отслеживание временных меток каждого запроса пользователя. 
Эти записи сохраняются, например, в таблицу и сортируются по времени; записи за пределами отслеживаемого интервала отбрасываются.
Когда поступает новый запрос, мы вычисляем количество записей, чтобы определить частоту запросов. Если запрос выходит за рамки допустимого количества, то он отбрасывается.


## Rate Limiting в распределенных системах

**Sticky session** — метод балансировки нагрузки, при котором запросы клиента передаются на один и тот же сервер группы.

Лучшим решением, которое допускает более гибкие правила распределения нагрузки, является **использование централизованного хранилища данных** (на ваш выбор).
В нём можно хранить счётчики количества запросов для каждого окна и пользователя. Основные проблемы этого подхода — это увеличение времени ответа из-за запросов к хранилищу и «race conditions».








